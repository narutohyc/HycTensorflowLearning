1）tflearn自定義loss function
Hi, you can add any new loss function to tflearn/objectives.py file 
(https://github.com/tflearn/tflearn/blob/master/tflearn/objectives.py). 
To use it, you just need to call its name in regression layer.

2）TensorFlow代码模板
    import tensorflow as tf
    # 这里写模型的主要算法
    def inference(X):
        # 计算输入 X 时，模型的输出
    def loss(X, Y):
        # 根据输入 X 和期望 Y 算出损失
    def input(total_loss):
        # 读取训练数据
    def train(total_loss):
        # 根据计算的总损失调整模型参数
    def evaluate(sess, X, Y):
        # 对模型进行评估
    # Saver 对象用于保存检查点
    saver = tf.train.Saver()
    with tf.Session() as sess:
        tf.initialize_all_variables().run()
        X, Y = inputs()
        # 好像少了个 inference，感觉应该是 total_loss = loss(inference(X), Y) 才对，算出来损失
        total_loss = loss(X, Y)
        # 根据损失调教模型
        train_op = train(total_loss)
        # TODO: 这个应该是多线程的代码？
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(sess=sess, coord=coord)

        # 训练次数
        training_steps = 1000
        # 使用 Saver 获取检查点
        initial_step = 0
        ckpt = tf.train.get_checkpoint_state(os.path.dirname(__file__))
        if chkpt and ckpt.model_checkpoint_path:
            saver.restore(sess, ckpt.model_checkpoint_path)
            initial_step = int(ckpt.model_checkpoint_path.rsplit('-', 1)[1])
        # 打印出每次训练的结果
        for step in range(initial_step, training_steps):
            sess.run([train_op])
            if step % 10 == 0:
                print "loss:", sess.run([total_loss])

        # 模型评估
        evaluate(sess, X, Y)
        # 每 1000 次训练保存检查点一次
        saver.save(sess, 'my-model', global_step=training_steps)
        saver.close()
        coord.request_stop()
        coord.join(threads)
        sess.close()

3）Tensor進行切片、concat和reshape
    1.切片(與數組操作無異)
      network[:, i, :, :, :]
    2.concat
      network = tf.concat([tensor0,tensor1,tensor2], axis=3)
    3.reshape
      tf.reshape(network, (m,n,q))

4）(int\float->Tensor) TensorFlow 张量类型转换
    from:https://www.w3cschool.cn/tensorflow_python/tensorflow_python-2t7u2cmq.html
    tf.bitcast
    bitcast(input，type，name=None)
    参见指南：张量变换
    在不复制数据的情况下，将张量从一种类型转换到另一种类型。
    给定张量输入，此操作返回的张量与数据类型的输入具有相同缓冲区信息。
    如果输入数据类型 T 大于输出数据类型，则形状将从 [...] 更改为 [...，sizeof（T）/ sizeof（type）]。
    如果 T 小于 type，则操作者要求最右边的维度等于 sizeof（type）/ sizeof（T）。然后形状从 [...，sizeof（type）/ sizeof（T）] 转到 [...]。
    注意：Bitcast 被当为低级的计算，因此具有不同字节序的机器将给出不同的结果。
    ARGS：
        input：张量。必须是下列类型之一：float32，float64，int64，int32，uint8，uint16，int16，int8，complex64，complex128，qint8，quint8，qint32，half。
        type：一个 tf.DType 来自：tf.float32, tf.float64, tf.int64, tf.int32, tf.uint8, tf.uint16, tf.int16, tf.int8, tf.complex64, tf.complex128, tf.qint8, tf.quint8, tf.qint32, tf.half。
        name：操作的名称（可选）。
    返回：
        返回 type 型张量。
        
    
    tf.cast(x, dtype, name=None)
    此函数是类型转换函数
    参数
        x：输入
        dtype：转换目标类型
        name：名称
    返回：Tensor
    例：
    # tensor `a` is [1.8, 2.2], dtype=tf.float  
        tf.cast(a, tf.int32) ==> [1, 2]  # dtype=tf.int32  
    
5）TensorFlow Data Input (Part 1): Placeholders, Protobufs & Queues_TFRecord
    https://indico.io/blog/tensorflow-data-inputs-part1-placeholders-protobufs-queues/
6）產生隨機數組
    import numpy as np
    for id in np.random.permutation(10):
        print(id)


7）反卷积和上采样比较
    http://www.52ml.net/20554.html
    def test():
        path = os.path.join(os.getcwd(), 'data/nyu_datasets/00000.jpg')
        from skimage import io
        image = io.imread(path)
        timage = tf.convert_to_tensor(np.reshape(image, [1, image.shape[0], image.shape[1], image.shape[2]]), tf.float32)
        from tflearn.layers.conv import upsample_2d,max_pool_2d
        with tf.Session() as sess:
            cv2.imshow('timage', sess.run(timage)[0, :, :, :]/255.0)
            cv2.waitKey()

            # kernel = tf.constant([0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0], shape=[3,3,3,1])
            kernel = tf.constant(0.2, shape=[3,3,3,1])
            convImg = tf.nn.conv2d(timage,kernel,strides=[1,3,3,1],padding='SAME')

            noupdeconvImg = tf.nn.conv2d_transpose(convImg,kernel,output_shape=[1, image.shape[0], image.shape[1], image.shape[2]],strides=[1,3,3,1],padding='SAME')
            cv2.imshow('noupdeconvImg', sess.run(noupdeconvImg)[0, :, :, :]/255.0)
            cv2.waitKey()

            # kernel = tf.constant(0.2, shape=[3,3,3,1])
            convImg = max_pool_2d(convImg,2,2)
            convImg = upsample_2d(convImg,2)
            deconvImg = tf.nn.conv2d_transpose(convImg,kernel,output_shape=[1, image.shape[0], image.shape[1], image.shape[2]],strides=[1,3,3,1],padding='SAME')

            cv2.imshow('convImg', sess.run(convImg)[0, :, :, :]/255.0)
            cv2.waitKey()

            cv2.imshow('deconvImg', sess.run(deconvImg)[0, :, :, :]/255.0)
            cv2.waitKey()

            upImg = upsample_2d(convImg,3)
            cv2.imshow('upImg', sess.run(upImg)[0, :, :, :]/255.0)
            cv2.waitKey()

        print('end test')



8）




9）









